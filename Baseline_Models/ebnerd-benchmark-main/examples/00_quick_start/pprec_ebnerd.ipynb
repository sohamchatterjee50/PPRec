{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "In this notebook, we illustrate how to use the Neural News Recommendation with Multi-Head Self-Attention ([NRMS](https://aclanthology.org/D19-1671/)). The implementation is taken from the [recommenders](https://github.com/recommenders-team/recommenders) repository. We have simply stripped the model to keep it cleaner.\n",
    "\n",
    "We use a small dataset, which is downloaded from [recsys.eb.dk](https://recsys.eb.dk/). All the datasets are stored in the folder path ```~/ebnerd_data/*```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_NER_COL\n",
    ")\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers, concat_list_to_text\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from ebrec.models.newsrec.dataloader import PPRecDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_pprec\n",
    "from ebrec.models.newsrec import PPRecModel\n",
    "from huggingface_hub import from_pretrained_keras\n",
    "\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/Users/sohamchatterjee/Documents/UvA/RecSYS/Project/ebnerd_data\")\n",
    "DATASPLIT = \"ebnerd_demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we sample the dataset, just to keep it smaller. Also, one can simply add the testset similary to the validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>1619579</td><td>[9770538, 9769306, â€¦ 9769622]</td><td>[9773084, 9771686, â€¦ 9771686]</td><td>[9773084]</td><td>310380206</td><td>[1, 0, â€¦ 0]</td></tr><tr><td>667805</td><td>[9769917, 9769433, â€¦ 9769433]</td><td>[9734283, 9773873, â€¦ 9734283]</td><td>[9773877]</td><td>215228693</td><td>[0, 0, â€¦ 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ user_id â”† article_id_fixed  â”† article_ids_invie â”† article_ids_clic â”† impression_id â”† labels      â”‚\n",
       "â”‚ ---     â”† ---               â”† w                 â”† ked              â”† ---           â”† ---         â”‚\n",
       "â”‚ u32     â”† list[i32]         â”† ---               â”† ---              â”† u32           â”† list[i8]    â”‚\n",
       "â”‚         â”†                   â”† list[i64]         â”† list[i64]        â”†               â”†             â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1619579 â”† [9770538,         â”† [9773084,         â”† [9773084]        â”† 310380206     â”† [1, 0, â€¦ 0] â”‚\n",
       "â”‚         â”† 9769306, â€¦        â”† 9771686, â€¦        â”†                  â”†               â”†             â”‚\n",
       "â”‚         â”† 9769622]          â”† 9771686]          â”†                  â”†               â”†             â”‚\n",
       "â”‚ 667805  â”† [9769917,         â”† [9734283,         â”† [9773877]        â”† 215228693     â”† [0, 0, â€¦ 0] â”‚\n",
       "â”‚         â”† 9769433, â€¦        â”† 9773873, â€¦        â”†                  â”†               â”†             â”‚\n",
       "â”‚         â”† 9769433]          â”† 9734283]          â”†                  â”†               â”†             â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "HISTORY_SIZE = 10\n",
    "FRACTION = 0.01\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[Î¼s]</td><td>bool</td><td>str</td><td>datetime[Î¼s]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3000022</td><td>&quot;Hanks beskyldtâ€¦</td><td>&quot;Tom Hanks har â€¦</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;Tom Hanks skulâ€¦</td><td>2006-09-20 09:24:18</td><td>[3518381]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[&quot;David Gardner&quot;]</td><td>[&quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, â€¦ &quot;Litteratur&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9911</td><td>&quot;Negative&quot;</td></tr><tr><td>3000063</td><td>&quot;Bostrups aske â€¦</td><td>&quot;StudievÃ¦rten bâ€¦</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;StrÃ¥lende sensâ€¦</td><td>2006-09-24 07:45:30</td><td>[3170935, 3170939]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, â€¦ &quot;Personlig begivenhed&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.5155</td><td>&quot;Neutral&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ article_i â”† title     â”† subtitle  â”† last_modi â”† â€¦ â”† total_pag â”† total_rea â”† sentiment â”† sentimen â”‚\n",
       "â”‚ d         â”† ---       â”† ---       â”† fied_time â”†   â”† eviews    â”† d_time    â”† _score    â”† t_label  â”‚\n",
       "â”‚ ---       â”† str       â”† str       â”† ---       â”†   â”† ---       â”† ---       â”† ---       â”† ---      â”‚\n",
       "â”‚ i32       â”†           â”†           â”† datetime[ â”†   â”† i32       â”† f32       â”† f32       â”† str      â”‚\n",
       "â”‚           â”†           â”†           â”† Î¼s]       â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 3000022   â”† Hanks     â”† Tom Hanks â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.9911    â”† Negative â”‚\n",
       "â”‚           â”† beskyldt  â”† har angiv â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† for misha â”† eligt     â”† 06:20:32  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† ndling    â”† mishandâ€¦  â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 3000063   â”† Bostrups  â”† StudievÃ¦r â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.5155    â”† Neutral  â”‚\n",
       "â”‚           â”† aske      â”† ten blev  â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† spredt i  â”† mindet    â”† 06:20:32  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† FuresÃ¸en  â”† med glaâ€¦  â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sohamchatterjee/miniforge3/envs/reco/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping_title = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached here\n"
     ]
    }
   ],
   "source": [
    "df_articles = concat_list_to_text(df_articles,'ner_clusters','ner_clusters_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 25)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th><th>subtitle-title</th><th>subtitle-title_encode_FacebookAI/xlm-roberta-base</th><th>ner_clusters_text</th><th>ner_clusters_text_encode_FacebookAI/xlm-roberta-base</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[Î¼s]</td><td>bool</td><td>str</td><td>datetime[Î¼s]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>list[i64]</td><td>str</td><td>list[i64]</td></tr></thead><tbody><tr><td>3000022</td><td>&quot;Hanks beskyldtâ€¦</td><td>&quot;Tom Hanks har â€¦</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;Tom Hanks skulâ€¦</td><td>2006-09-20 09:24:18</td><td>[3518381]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[&quot;David Gardner&quot;]</td><td>[&quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, â€¦ &quot;Litteratur&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9911</td><td>&quot;Negative&quot;</td><td>&quot;Tom Hanks har â€¦</td><td>[8352, 2548, â€¦ 56]</td><td>&quot;David Gardner&quot;</td><td>[6765, 90968, â€¦ 1]</td></tr><tr><td>3000063</td><td>&quot;Bostrups aske â€¦</td><td>&quot;StudievÃ¦rten bâ€¦</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;StrÃ¥lende sensâ€¦</td><td>2006-09-24 07:45:30</td><td>[3170935, 3170939]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, â€¦ &quot;Personlig begivenhed&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.5155</td><td>&quot;Neutral&quot;</td><td>&quot;StudievÃ¦rten bâ€¦</td><td>[60716, 17052, â€¦ 1]</td><td>&quot;&quot;</td><td>[1, 1, â€¦ 1]</td></tr><tr><td>3000613</td><td>&quot;Jesper Olsen râ€¦</td><td>&quot;Den tidligere â€¦</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Jesper Olsen, â€¦</td><td>2006-05-09 11:29:00</td><td>[3164998]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[&quot;Frankrig&quot;, &quot;Jesper Olsen&quot;, â€¦ &quot;Jesper Olsen&quot;]</td><td>[&quot;LOC&quot;, &quot;PER&quot;, â€¦ &quot;PER&quot;]</td><td>[&quot;Kendt&quot;, &quot;Sport&quot;, â€¦ &quot;Sygdom og behandling&quot;]</td><td>142</td><td>[196, 271]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9876</td><td>&quot;Negative&quot;</td><td>&quot;Den tidligere â€¦</td><td>[1575, 12532, â€¦ 111326]</td><td>&quot;Frankrig-Jespeâ€¦</td><td>[192380, 9, â€¦ 1]</td></tr><tr><td>3000700</td><td>&quot;Madonna toplÃ¸sâ€¦</td><td>&quot;47-Ã¥rige Madonâ€¦</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Skal du have sâ€¦</td><td>2006-05-04 11:03:12</td><td>[3172046]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Livsstil&quot;, &quot;Underholdning&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8786</td><td>&quot;Neutral&quot;</td><td>&quot;47-Ã¥rige Madonâ€¦</td><td>[7657, 9, â€¦ 22907]</td><td>&quot;&quot;</td><td>[1, 1, â€¦ 1]</td></tr><tr><td>3000840</td><td>&quot;Otto Brandenbuâ€¦</td><td>&quot;Sangeren og skâ€¦</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;&#x27;Og lidt for Sâ€¦</td><td>2007-03-01 18:34:00</td><td>[3914446]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, â€¦ &quot;Musik og lyd&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9468</td><td>&quot;Negative&quot;</td><td>&quot;Sangeren og skâ€¦</td><td>[22986, 3683, â€¦ 1]</td><td>&quot;&quot;</td><td>[1, 1, â€¦ 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 25)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ article_i â”† title     â”† subtitle  â”† last_modi â”† â€¦ â”† subtitle- â”† subtitle- â”† ner_clust â”† ner_clus â”‚\n",
       "â”‚ d         â”† ---       â”† ---       â”† fied_time â”†   â”† title     â”† title_enc â”† ers_text  â”† ters_tex â”‚\n",
       "â”‚ ---       â”† str       â”† str       â”† ---       â”†   â”† ---       â”† ode_Faceb â”† ---       â”† t_encode â”‚\n",
       "â”‚ i32       â”†           â”†           â”† datetime[ â”†   â”† str       â”† ookAIâ€¦    â”† str       â”† _Faceboo â”‚\n",
       "â”‚           â”†           â”†           â”† Î¼s]       â”†   â”†           â”† ---       â”†           â”† â€¦        â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”†           â”† list[i64] â”†           â”† ---      â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”† list[i64 â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”† ]        â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 3000022   â”† Hanks     â”† Tom Hanks â”† 2023-06-2 â”† â€¦ â”† Tom Hanks â”† [8352,    â”† David     â”† [6765,   â”‚\n",
       "â”‚           â”† beskyldt  â”† har angiv â”† 9         â”†   â”† har angiv â”† 2548, â€¦   â”† Gardner   â”† 90968, â€¦ â”‚\n",
       "â”‚           â”† for misha â”† eligt     â”† 06:20:32  â”†   â”† eligt     â”† 56]       â”†           â”† 1]       â”‚\n",
       "â”‚           â”† ndling    â”† mishandâ€¦  â”†           â”†   â”† mishandâ€¦  â”†           â”†           â”†          â”‚\n",
       "â”‚ 3000063   â”† Bostrups  â”† StudievÃ¦r â”† 2023-06-2 â”† â€¦ â”† StudievÃ¦r â”† [60716,   â”†           â”† [1, 1, â€¦ â”‚\n",
       "â”‚           â”† aske      â”† ten blev  â”† 9         â”†   â”† ten blev  â”† 17052, â€¦  â”†           â”† 1]       â”‚\n",
       "â”‚           â”† spredt i  â”† mindet    â”† 06:20:32  â”†   â”† mindet    â”† 1]        â”†           â”†          â”‚\n",
       "â”‚           â”† FuresÃ¸en  â”† med glaâ€¦  â”†           â”†   â”† med glaâ€¦  â”†           â”†           â”†          â”‚\n",
       "â”‚ 3000613   â”† Jesper    â”† Den       â”† 2023-06-2 â”† â€¦ â”† Den       â”† [1575,    â”† Frankrig- â”† [192380, â”‚\n",
       "â”‚           â”† Olsen     â”† tidligere â”† 9         â”†   â”† tidligere â”† 12532, â€¦  â”† Jesper    â”† 9, â€¦ 1]  â”‚\n",
       "â”‚           â”† ramt af   â”† danske    â”† 06:20:33  â”†   â”† danske    â”† 111326]   â”† Olsen-Jes â”†          â”‚\n",
       "â”‚           â”† hjerneblÃ¸ â”† landshold â”†           â”†   â”† landshold â”†           â”† per Olsâ€¦  â”†          â”‚\n",
       "â”‚           â”† dnâ€¦       â”† ssâ€¦       â”†           â”†   â”† ssâ€¦       â”†           â”†           â”†          â”‚\n",
       "â”‚ 3000700   â”† Madonna   â”† 47-Ã¥rige  â”† 2023-06-2 â”† â€¦ â”† 47-Ã¥rige  â”† [7657, 9, â”†           â”† [1, 1, â€¦ â”‚\n",
       "â”‚           â”† toplÃ¸s    â”† Madonna   â”† 9         â”†   â”† Madonna   â”† â€¦ 22907]  â”†           â”† 1]       â”‚\n",
       "â”‚           â”† med heste â”† poserer   â”† 06:20:33  â”†   â”† poserer   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”† bÃ¥de toâ€¦  â”†           â”†   â”† bÃ¥de toâ€¦  â”†           â”†           â”†          â”‚\n",
       "â”‚ 3000840   â”† Otto Bran â”† Sangeren  â”† 2023-06-2 â”† â€¦ â”† Sangeren  â”† [22986,   â”†           â”† [1, 1, â€¦ â”‚\n",
       "â”‚           â”† denburg   â”† og skuesp â”† 9         â”†   â”† og skuesp â”† 3683, â€¦   â”†           â”† 1]       â”‚\n",
       "â”‚           â”† er dÃ¸d    â”† illeren   â”† 06:20:33  â”†   â”† illeren   â”† 1]        â”†           â”†          â”‚\n",
       "â”‚           â”†           â”† Otto Bâ€¦   â”†           â”†   â”† Otto Bâ€¦   â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, 'ner_clusters_text', max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "df_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_mapping_entity = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = PPRecDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping_title,\n",
    "    body_mapping=article_mapping_entity,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=64,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = PPRecDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping_title,\n",
    "    body_mapping=article_mapping_entity,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PPRecModel(\n",
    "#     hparams=hparams_pprec,\n",
    "#     word2vec_embedding=None,\n",
    "#     seed=42,\n",
    "# )\n",
    "# print(\"Model:\",model.model)\n",
    "# print(\"Scorer:\",model.scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"PPRecModel\"\n",
    "LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = f\"downloads/data/state_dict/{MODEL_NAME}/weights\"\n",
    "\n",
    "# CALLBACKS\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    ")\n",
    "\n",
    "hparams_pprec.history_size = HISTORY_SIZE\n",
    "model = PPRecModel(\n",
    "    hparams=hparams_pprec,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Cannot serialize object <ebrec.models.newsrec.pprec.PPRecModel object at 0x2a1bafa90> of type <class 'ebrec.models.newsrec.pprec.PPRecModel'>. To be serializable, a class must implement the `get_config()` method.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Cannot serialize object <ebrec.models.newsrec.pprec.PPRecModel object at 0x2a1bafa90> of type <class 'ebrec.models.newsrec.pprec.PPRecModel'>. To be serializable, a class must implement the `get_config()` method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "1/4 [======>.......................] - ETA: 17s - loss: 1.7649Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6810Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "['title_user_id', 'title_article_ids_clicked', 'title_impression_id', 'title_n_samples', 'title_article_id_fixed', 'title_article_ids_inview', 'ner_clusters_text_user_id', 'ner_clusters_text_article_ids_clicked', 'ner_clusters_text_impression_id', 'ner_clusters_text_n_samples', 'ner_clusters_text_article_id_fixed', 'ner_clusters_text_article_ids_inview']\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "['title_user_id', 'title_article_ids_clicked', 'title_impression_id', 'title_n_samples', 'title_article_id_fixed', 'title_article_ids_inview', 'ner_clusters_text_user_id', 'ner_clusters_text_article_ids_clicked', 'ner_clusters_text_impression_id', 'ner_clusters_text_n_samples', 'ner_clusters_text_article_id_fixed', 'ner_clusters_text_article_ids_inview']\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "['title_user_id', 'title_article_ids_clicked', 'title_impression_id', 'title_n_samples', 'title_article_id_fixed', 'title_article_ids_inview', 'ner_clusters_text_user_id', 'ner_clusters_text_article_ids_clicked', 'ner_clusters_text_impression_id', 'ner_clusters_text_n_samples', 'ner_clusters_text_article_id_fixed', 'ner_clusters_text_article_ids_inview']\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "['title_user_id', 'title_article_ids_clicked', 'title_impression_id', 'title_n_samples', 'title_article_id_fixed', 'title_article_ids_inview', 'ner_clusters_text_user_id', 'ner_clusters_text_article_ids_clicked', 'ner_clusters_text_impression_id', 'ner_clusters_text_n_samples', 'ner_clusters_text_article_id_fixed', 'ner_clusters_text_article_ids_inview']\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "['title_user_id', 'title_article_ids_clicked', 'title_impression_id', 'title_n_samples', 'title_article_id_fixed', 'title_article_ids_inview', 'ner_clusters_text_user_id', 'ner_clusters_text_article_ids_clicked', 'ner_clusters_text_impression_id', 'ner_clusters_text_n_samples', 'ner_clusters_text_article_id_fixed', 'ner_clusters_text_article_ids_inview']\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "['title_user_id', 'title_article_ids_clicked', 'title_impression_id', 'title_n_samples', 'title_article_id_fixed', 'title_article_ids_inview', 'ner_clusters_text_user_id', 'ner_clusters_text_article_ids_clicked', 'ner_clusters_text_impression_id', 'ner_clusters_text_n_samples', 'ner_clusters_text_article_id_fixed', 'ner_clusters_text_article_ids_inview']\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "['title_user_id', 'title_article_ids_clicked', 'title_impression_id', 'title_n_samples', 'title_article_id_fixed', 'title_article_ids_inview', 'ner_clusters_text_user_id', 'ner_clusters_text_article_ids_clicked', 'ner_clusters_text_impression_id', 'ner_clusters_text_n_samples', 'ner_clusters_text_article_id_fixed', 'ner_clusters_text_article_ids_inview']\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "['title_user_id', 'title_article_ids_clicked', 'title_impression_id', 'title_n_samples', 'title_article_id_fixed', 'title_article_ids_inview', 'ner_clusters_text_user_id', 'ner_clusters_text_article_ids_clicked', 'ner_clusters_text_impression_id', 'ner_clusters_text_n_samples', 'ner_clusters_text_article_id_fixed', 'ner_clusters_text_article_ids_inview']\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "['title_user_id', 'title_article_ids_clicked', 'title_impression_id', 'title_n_samples', 'title_article_id_fixed', 'title_article_ids_inview', 'ner_clusters_text_user_id', 'ner_clusters_text_article_ids_clicked', 'ner_clusters_text_impression_id', 'ner_clusters_text_n_samples', 'ner_clusters_text_article_id_fixed', 'ner_clusters_text_article_ids_inview']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=1,\n",
    "    callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_validation = model.scorer.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the predictions to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "#     add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    "# )\n",
    "# df_validation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = MetricEvaluator(\n",
    "#     labels=df_validation[\"labels\"].to_list(),\n",
    "#     predictions=df_validation[\"scores\"].to_list(),\n",
    "#     metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    "# )\n",
    "# metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_validation = df_validation.with_columns(\n",
    "#     pl.col(\"scores\")\n",
    "#     .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "#     .alias(\"ranked_scores\")\n",
    "# )\n",
    "# df_validation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using the validation, simply add the testset to your flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_submission_file(\n",
    "#     impression_ids=df_validation[DEFAULT_IMPRESSION_ID_COL],\n",
    "#     prediction_scores=df_validation[\"ranked_scores\"],\n",
    "#     path=\"downloads/predictions.txt\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
