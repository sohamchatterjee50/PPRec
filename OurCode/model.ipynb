{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.model.news_encoder import LookupNewsEncoder, NEConfig\n",
    "from src.model.user_encoder import (\n",
    "    NewsSelfAttention,\n",
    "    PopularityEmbedding,\n",
    "    PopularityAwareUserEncoder,\n",
    "    ContentPopularityJointAttention,\n",
    "    CPJAConfig,\n",
    "    PEConfig,\n",
    "    NSAConfig,\n",
    "    PAUEConfig,\n",
    ")\n",
    "from src.model.popularity_predictor import TimeAwareNewsPopularityPredictor, TANPPConfig\n",
    "\n",
    "from src.data.split import EBNeRDSplit\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = EBNeRDSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings defined in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_embedding_size = 100\n",
    "recency_embedding_size = 100\n",
    "n_attention_heads = 20\n",
    "head_output_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings found in their code\n",
    "\n",
    "In `Encoders.py`, function `create_pe_model`, lines creating variables `time_embedding_layer` and `population_embedding_layer`. Don't fully get it all though.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ctr = 200\n",
    "max_recency = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LookupNewsEncoder(\n",
      "  (fcout): Linear(in_features=768, out_features=400, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "    Songga told us to first use the premade article embedding in one\n",
      "    of the artifacts as a newencoder.\n",
      "\n",
      "    So this news encoder lookes up the embeddings of the articles in\n",
      "    the data artifact and convert them to the desired size, using a\n",
      "    fully connected layer.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        Returns n (the news encodings) for a batch of articles.\n",
      "\n",
      "        n has shape (batch_size, embedding_size),\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "news_encoder_config = NEConfig(\n",
    "    n_attention_heads=n_attention_heads,\n",
    "    head_output_size=head_output_size,\n",
    ")\n",
    "lookup_news_encoder = LookupNewsEncoder(\"bert\", news_encoder_config, device=torch.device(\"cpu\"))\n",
    "print(lookup_news_encoder)\n",
    "print(lookup_news_encoder.__doc__)\n",
    "print(lookup_news_encoder.forward.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_article_id = split.get_random_article_id()\n",
    "news_embeddings = lookup_news_encoder.forward([random_article_id])\n",
    "news_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clicks_in_user_history = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Self Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewsSelfAttention()\n",
      "\n",
      "\n",
      "    Implementation of the news self-attention module for\n",
      "    the popularity-aware user encoder.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        Calculates the contextual news representations m, based on the\n",
      "        news embeddings n outputted by the news encoder.\n",
      "\n",
      "        n is a tensor of shape (batch_size, N, news_embedding_size)\n",
      "        m is a tensor of shape (batch_size, N, head_output_size * n_attention_heads)\n",
      "        where N is the number of clicked articles by the user.\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "news_self_attention_config = NSAConfig(\n",
    "    n_size=news_encoder_config.get_size_n(),\n",
    "    n_attention_heads=n_attention_heads,\n",
    "    head_output_size=head_output_size,\n",
    ")\n",
    "news_self_attention = NewsSelfAttention(news_self_attention_config)\n",
    "print(news_self_attention)\n",
    "print(news_self_attention.__doc__)\n",
    "print(news_self_attention.forward.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 400])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = news_embeddings.unsqueeze(1).repeat(\n",
    "    1,\n",
    "    n_clicks_in_user_history,\n",
    "    1,\n",
    ")\n",
    "contextual_news_embeddings = news_self_attention.forward(n)\n",
    "contextual_news_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PopularityEmbedding(\n",
      "  (embedding): Embedding(200, 100)\n",
      ")\n",
      "\n",
      "\n",
      "    Implementation of the popularity embedding module for the popularity-aware user encoder.\n",
      "\n",
      "    \"Second, we uniformly quantify the popularity of the i-th clicked news predicted by\n",
      "    the time-aware news popularity predictor and convert it into an embedding vector $p_i$\n",
      "    via popularity embedding.\"\n",
      "\n",
      "    They also leave a footnote, right after 'popularity predictor'.\n",
      "\n",
      "    \"We remove news recency and content here to avoid non-differentiable quantization operation.\"\n",
      "\n",
      "    I don't really get this, how is the does anything here. To me it just seems like we have\n",
      "    to use the click though rates with this Embedding layer.\n",
      "\n",
      "    Q: What has the popularity predictor to do with the popularity embedding?\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        Calculates the popularity embeddings p based on the click through rate\n",
      "        of every article.\n",
      "\n",
      "        ctr is a tensor of shape (batch_size, N), where N is the number\n",
      "        of clicked articles by the user. The values in ctr are the click through\n",
      "        rates of the articles, so they are integers. I thought at first the ctr\n",
      "        would be some kind of division between clicks and impressions, but it seems\n",
      "        like its just the number of clicks in some period? Got this from looking at\n",
      "        their code. They must be integers to be used in this kind of embedding layer.\n",
      "\n",
      "        p is a vector of shape (batch_size, N, popularity_embedding_size)\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "popularity_embedding_config = PEConfig(\n",
    "    p_size=popularity_embedding_size, max_ctr=max_ctr\n",
    ")\n",
    "popularity_embedding = PopularityEmbedding(popularity_embedding_config)\n",
    "print(popularity_embedding)\n",
    "print(popularity_embedding.__doc__)\n",
    "print(popularity_embedding.forward.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m popularity_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m popularity_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mpopularity_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopularity_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m popularity_embeddings\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/Desktop/School/RecSys/GithubRepo/OurCode/src/model/user_encoder.py:97\u001b[0m, in \u001b[0;36mPopularityEmbedding.forward\u001b[0;34m(self, ctr)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ctr\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     96\u001b[0m batch_size, N \u001b[38;5;241m=\u001b[39m ctr\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m ctr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint64 \u001b[38;5;129;01mor\u001b[39;00m ctr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint32\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# The embedding layer has a specific max value, so we have to clip the ctr\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ctr_clipped \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(ctr, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_ctr \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "popularity_scores = torch.randint(0, max_ctr, (1, 1))\n",
    "popularity_embeddings = popularity_embedding.forward(popularity_scores)\n",
    "popularity_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Popularity Join Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentPopularityJointAttention()\n",
      "\n",
      "\n",
      "    Implementation of the content-popularity joint attention module\n",
      "    for the popularity-aware user encoder.\n",
      "\n",
      "    This is based on formula (2) in 3.4 of the paper.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        Calculates the user interest embeddings u, based on the\n",
      "        the popularity embeddings p, and the contextual news\n",
      "        representations m.\n",
      "\n",
      "        m is a tensor of shape (batch_size, N, m_size)\n",
      "        p is a tensor of shape (batch_size, N, p_size)\n",
      "        u is a tensor of shape (batch_size, m_size)\n",
      "        where N is the number of clicked articles by the user.\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "cpja_config = CPJAConfig(\n",
    "    p_size=popularity_embedding_config.p_size,\n",
    "    m_size=news_self_attention_config.get_size_m(),\n",
    "    # The paper doesnt specify a default I think\n",
    "    weight_size=100,\n",
    ")\n",
    "cpja = ContentPopularityJointAttention(cpja_config)\n",
    "print(cpja)\n",
    "print(cpja.__doc__)\n",
    "print(cpja.forward.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user_interests \u001b[38;5;241m=\u001b[39m \u001b[43mcpja\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontextual_news_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopularity_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m user_interests\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/Desktop/School/RecSys/GithubRepo/OurCode/src/model/user_encoder.py:353\u001b[0m, in \u001b[0;36mContentPopularityJointAttention.forward\u001b[0;34m(self, m, p)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(p\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m p\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m batch_size\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m p\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m N\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m p\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mp_size\n\u001b[1;32m    356\u001b[0m mp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((m, p), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (batch_size, N, m_size + p_size)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "user_interests = cpja.forward(contextual_news_embeddings, popularity_embeddings)\n",
    "user_interests.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TANPPConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m time_aware_news_popularity_predictor_config \u001b[38;5;241m=\u001b[39m \u001b[43mTANPPConfig\u001b[49m(\n\u001b[1;32m      2\u001b[0m     r_size\u001b[38;5;241m=\u001b[39mrecency_embedding_size,\n\u001b[1;32m      3\u001b[0m     n_size\u001b[38;5;241m=\u001b[39mnews_encoder_config\u001b[38;5;241m.\u001b[39mget_size_n(),\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m time_aware_news_populariry_predictor \u001b[38;5;241m=\u001b[39m TimeAwareNewsPopularityPredictor(\n\u001b[1;32m      7\u001b[0m     time_aware_news_popularity_predictor_config\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TANPPConfig' is not defined"
     ]
    }
   ],
   "source": [
    "time_aware_news_popularity_predictor_config = TANPPConfig(\n",
    "    r_size=recency_embedding_size,\n",
    "    n_size=news_encoder_config.get_size_n(),\n",
    ")\n",
    "\n",
    "time_aware_news_populariry_predictor = TimeAwareNewsPopularityPredictor(\n",
    "    time_aware_news_popularity_predictor_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
