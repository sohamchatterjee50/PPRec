{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.model.news_encoder import LookupNewsEncoder, NEConfig\n",
    "from src.model.user_encoder import (\n",
    "    NewsSelfAttention,\n",
    "    PopularityEmbedding,\n",
    "    PopularityAwareUserEncoder,\n",
    "    ContentPopularityJointAttention,\n",
    "    CPJAConfig,\n",
    "    PEConfig,\n",
    "    NSAConfig,\n",
    "    PAUEConfig,\n",
    ")\n",
    "\n",
    "from src.data.split import EBNeRDSplit\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = EBNeRDSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LookupNewsEncoder(\n",
      "  (fcout): Linear(in_features=768, out_features=400, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "    Songga told us to first use the premade article embedding in one\n",
      "    of the artifacts as a newencoder.\n",
      "\n",
      "    So this news encoder lookes up the embeddings of the articles in\n",
      "    the data artifact and convert them to the desired size, using a\n",
      "    fully connected layer.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        Returns n (the news encodings) for a batch of articles.\n",
      "\n",
      "        n has shape (batch_size, embedding_size), where embedding_size\n",
      "        is 400 by default.\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "news_encoder_config = NEConfig()\n",
    "lookup_news_encoder = LookupNewsEncoder(\"bert\", news_encoder_config)\n",
    "print(lookup_news_encoder)\n",
    "print(lookup_news_encoder.__doc__)\n",
    "print(lookup_news_encoder.forward.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_article_id = split.get_random_article_id()\n",
    "news_embeddings = lookup_news_encoder.forward([random_article_id])\n",
    "news_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clicks_in_user_history = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Self Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewsSelfAttention()\n",
      "\n",
      "\n",
      "    Implementation of the news self-attention module for\n",
      "    the popularity-aware user encoder.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        Calculates the contextual news representations m, based on the\n",
      "        news embeddings n outputted by the news encoder.\n",
      "\n",
      "        n is a tensor of shape (batch_size, N, news_embedding_size)\n",
      "        m is a tensor of shape (batch_size, N, head_output_size * n_attention_heads)\n",
      "        where N is the number of clicked articles by the user.\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "news_self_attention_config = NSAConfig(n_size=news_encoder_config.get_size_n())\n",
    "news_self_attention = NewsSelfAttention(news_self_attention_config)\n",
    "print(news_self_attention)\n",
    "print(news_self_attention.__doc__)\n",
    "print(news_self_attention.forward.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 20, 20])\n",
      "400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 400])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = news_embeddings.unsqueeze(1).repeat(\n",
    "    1,\n",
    "    n_clicks_in_user_history,\n",
    "    1,\n",
    ")\n",
    "contextual_news_embeddings = news_self_attention.forward(n)\n",
    "contextual_news_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PopularityEmbedding()\n",
      "\n",
      "\n",
      "    Implementation of the popularity embedding module for the popularity-aware user encoder.\n",
      "\n",
      "    Here, as stated in the paper, news recency and content are removed, to avoid non-\n",
      "    differentiable quantization operations. So only the click-through rate is used\n",
      "    in the popularity predictor to calculate the popularity score $s_p$.\n",
      "\n",
      "    This module does not implement the popularity predictor, this is implemented in\n",
      "    popularity_predictor.py. But this module does implement the conversion from the\n",
      "    popularity scores to the popularity embeddings, via a simple linear transformation.\n",
      "\n",
      "    We discussed with Songga that this is probably the way they implemented it, since\n",
      "    the paper doesn't specifically discuss how this conversion is done. All it states is:\n",
      "\n",
      "    \"Second, we uniformly quantify the popularity of the i-th clicked news predicted by\n",
      "    the time-aware news popularity predictor and convert it into an embedding vector $p_i$\n",
      "    via popularity embedding.\"\n",
      "\n",
      "    They also leave a footnote, right after 'popularity predictor'.\n",
      "\n",
      "    \"We remove news recency and content here to avoid non-differentiable quantization operation.\"\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        Calculates the popularity embeddings p based on the popularity scores sp.\n",
      "        These popularity scores are the output of the popularity predictor, but this\n",
      "        time should only be calculated based on the click-through rate, to avoid\n",
      "        non-differentiable quantization operations.\n",
      "\n",
      "        sp is a tensor of shape (batch_size, N), where N is the number\n",
      "        of clicked articles by the user.\n",
      "\n",
      "        p is a vector of shape (batch_size, N, popularity_embedding_size)\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "popularity_embedding_config = PEConfig()\n",
    "popularity_embedding = PopularityEmbedding(popularity_embedding_config)\n",
    "print(popularity_embedding)\n",
    "print(popularity_embedding.__doc__)\n",
    "print(popularity_embedding.forward.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity_scores = torch.rand(1, 1)\n",
    "popularity_embeddings = popularity_embedding.forward(popularity_scores)\n",
    "popularity_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Popularity Join Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentPopularityJointAttention()\n",
      "\n",
      "\n",
      "    Implementation of the content-popularity joint attention module\n",
      "    for the popularity-aware user encoder.\n",
      "\n",
      "    This is based on formula (2) in 3.4 of the paper.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        Calculates the user interest embeddings u, based on the\n",
      "        the popularity embeddings p, and the contextual news\n",
      "        representations m.\n",
      "\n",
      "        m is a tensor of shape (batch_size, N, m_size)\n",
      "        p is a tensor of shape (batch_size, N, p_size)\n",
      "        u is a tensor of shape (batch_size, m_size)\n",
      "        where N is the number of clicked articles by the user.\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "cpja_config = CPJAConfig(\n",
    "    p_size=popularity_embedding_config.p_size,\n",
    "    m_size=news_self_attention_config.get_size_m(),\n",
    ")\n",
    "cpja = ContentPopularityJointAttention(cpja_config)\n",
    "print(cpja)\n",
    "print(cpja.__doc__)\n",
    "print(cpja.forward.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_interests = cpja.forward(contextual_news_embeddings, popularity_embeddings)\n",
    "user_interests.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
