{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.model.dataloader import PPRecDataLoader\n",
    "from src.model.model_config import hparams_pprec\n",
    "from model.modules import PPRec\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "import polars as pl\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ARTICLE_MODIFIED_TIMESTAMP_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_IMPRESSION_TIMESTAMP_COL\n",
    ")\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "\n",
    "saved_model = PPRec(hparams_pprec,word2vec_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'model_20240618_011912_0'\n",
    "saved_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "article_mapping_title, article_mapping_entity, articles_ctr, popularity_mapping = {},{},{},{}\n",
    "with open('article_mapping_title.pkl', 'rb') as handle:\n",
    "    article_mapping_title = pickle.load(handle)\n",
    "with open('article_mapping_entity.pkl', 'rb') as handle:\n",
    "    article_mapping_entity = pickle.load(handle)\n",
    "with open('articles_ctr.pkl', 'rb') as handle:\n",
    "    articles_ctr = pickle.load(handle)\n",
    "with open('popularity_mapping.pkl', 'rb') as handle:\n",
    "    popularity_mapping = pickle.load(handle)\n",
    "\n",
    "COLUMNS = [\n",
    "   'user_id',\n",
    "   'article_id_fixed',\n",
    "   'article_ids_inview',\n",
    "   'article_ids_clicked',\n",
    "   'impression_id',\n",
    "   'labels',\n",
    "   'recency_inview',\n",
    "   'recency_hist'  \n",
    "]\n",
    "\n",
    "\n",
    "df_validation =  pl.scan_parquet(\"small_demo_val_all_features_with_sampling.parquet\").select(COLUMNS).collect()\n",
    "\n",
    "val_dataloader = PPRecDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping_title,\n",
    "    entity_mapping=article_mapping_entity,\n",
    "    ctr_mapping=articles_ctr,\n",
    "    popularity_mapping = popularity_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    history_recency = 'recency_hist',\n",
    "    inview_recency = 'recency_inview',\n",
    "    eval_mode=True,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n",
      "Reached here\n"
     ]
    }
   ],
   "source": [
    "saved_model.eval()\n",
    "\n",
    "predictions = np.empty(shape=(4,5))\n",
    "with torch.no_grad():\n",
    "    for i, vdata in enumerate(val_dataloader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vtitle = vinputs[5]\n",
    "            ventities = vinputs[6]\n",
    "            vctr = vinputs[7]\n",
    "            vrecency = vinputs[8]\n",
    "            vhist_title = vinputs[0]\n",
    "            vhist_popularity = vinputs[2]\n",
    "\n",
    "            vtitle = torch.from_numpy(vtitle)\n",
    "            ventities = torch.from_numpy(ventities)\n",
    "            vctr = torch.from_numpy(vctr)\n",
    "            vrecency = torch.from_numpy(vrecency)\n",
    "            vhist_title = torch.from_numpy(vhist_title)\n",
    "            vhist_popularity = torch.from_numpy(vhist_popularity)\n",
    "            vlabels = torch.from_numpy(vlabels)\n",
    "        \n",
    "            # vtitle = vtitle.to(device)\n",
    "            # ventities = ventities.to(device)\n",
    "            # vctr = vctr.to(device)\n",
    "            # vrecency = vrecency.to(device)\n",
    "            # vhist_title = vhist_title.to(device)\n",
    "            # vhist_popularity = vhist_popularity.to(device)\n",
    "            # vlabels = vlabels.to(device)\n",
    "\n",
    "\n",
    "            outputs = saved_model(vtitle, ventities, vctr, vrecency , vhist_title, vhist_popularity).cpu().detach().numpy()\n",
    "            predictions = np.concatenate([predictions,outputs],axis=0)\n",
    "            \n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictions[4:]\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_validation.with_columns(pl.Series(name=\"predicted_scores\", values=predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th><th>recency_inview</th><th>recency_hist</th><th>predicted_scores</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td><td>list[i64]</td><td>list[i64]</td><td>list[f64]</td></tr></thead><tbody><tr><td>2052088</td><td>[9778952, 9777636, … 9779577]</td><td>[9777705, 9786209, … 9786230]</td><td>[9786172]</td><td>69798187</td><td>[0, 0, … 0]</td><td>[3, 0, … 1]</td><td>[1, 0, … 1]</td><td>[0.402318, 0.095339, … 0.352166]</td></tr><tr><td>1622906</td><td>[9779285, 9779181, … 9779748]</td><td>[9789745, 9789702, … 9789676]</td><td>[9789702]</td><td>571539786</td><td>[0, 1, … 0]</td><td>[0, 1, … 1]</td><td>[0, 1, … 1]</td><td>[0.398743, 0.097287, … 0.351678]</td></tr><tr><td>667805</td><td>[9779427, 9780195, … 9780195]</td><td>[9783213, 9783213, … 9726237]</td><td>[9782092]</td><td>396061188</td><td>[0, 0, … 0]</td><td>[1, 1, … 0]</td><td>[8, 0, … 0]</td><td>[0.397379, 0.092174, … 0.350979]</td></tr><tr><td>1887792</td><td>[9778369, 9778381, … 9778971]</td><td>[9782879, 9780968, … 9782695]</td><td>[9782695]</td><td>369793739</td><td>[0, 0, … 1]</td><td>[3, 3, … 4]</td><td>[4, 10, … 7]</td><td>[0.407408, 0.088169, … 0.358567]</td></tr><tr><td>1216284</td><td>[9778769, 9778745, … 9778827]</td><td>[7213923, 9052240, … 9780651]</td><td>[9780651]</td><td>142351970</td><td>[0, 0, … 1]</td><td>[42295, 12288, … 0]</td><td>[0, 0, … 1]</td><td>[0.40595, 0.09089, … 0.347896]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ user_id ┆ article_id ┆ article_i ┆ article_i ┆ … ┆ labels    ┆ recency_i ┆ recency_h ┆ predicted │\n",
       "│ ---     ┆ _fixed     ┆ ds_inview ┆ ds_clicke ┆   ┆ ---       ┆ nview     ┆ ist       ┆ _scores   │\n",
       "│ u32     ┆ ---        ┆ ---       ┆ d         ┆   ┆ list[i8]  ┆ ---       ┆ ---       ┆ ---       │\n",
       "│         ┆ list[i32]  ┆ list[i64] ┆ ---       ┆   ┆           ┆ list[i64] ┆ list[i64] ┆ list[f64] │\n",
       "│         ┆            ┆           ┆ list[i64] ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 2052088 ┆ [9778952,  ┆ [9777705, ┆ [9786172] ┆ … ┆ [0, 0, …  ┆ [3, 0, …  ┆ [1, 0, …  ┆ [0.402318 │\n",
       "│         ┆ 9777636, … ┆ 9786209,  ┆           ┆   ┆ 0]        ┆ 1]        ┆ 1]        ┆ ,         │\n",
       "│         ┆ 9779577]   ┆ …         ┆           ┆   ┆           ┆           ┆           ┆ 0.095339, │\n",
       "│         ┆            ┆ 9786230]  ┆           ┆   ┆           ┆           ┆           ┆ …         │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆           ┆ 0.352166] │\n",
       "│ 1622906 ┆ [9779285,  ┆ [9789745, ┆ [9789702] ┆ … ┆ [0, 1, …  ┆ [0, 1, …  ┆ [0, 1, …  ┆ [0.398743 │\n",
       "│         ┆ 9779181, … ┆ 9789702,  ┆           ┆   ┆ 0]        ┆ 1]        ┆ 1]        ┆ ,         │\n",
       "│         ┆ 9779748]   ┆ …         ┆           ┆   ┆           ┆           ┆           ┆ 0.097287, │\n",
       "│         ┆            ┆ 9789676]  ┆           ┆   ┆           ┆           ┆           ┆ …         │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆           ┆ 0.351678] │\n",
       "│ 667805  ┆ [9779427,  ┆ [9783213, ┆ [9782092] ┆ … ┆ [0, 0, …  ┆ [1, 1, …  ┆ [8, 0, …  ┆ [0.397379 │\n",
       "│         ┆ 9780195, … ┆ 9783213,  ┆           ┆   ┆ 0]        ┆ 0]        ┆ 0]        ┆ ,         │\n",
       "│         ┆ 9780195]   ┆ …         ┆           ┆   ┆           ┆           ┆           ┆ 0.092174, │\n",
       "│         ┆            ┆ 9726237]  ┆           ┆   ┆           ┆           ┆           ┆ …         │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆           ┆ 0.350979] │\n",
       "│ 1887792 ┆ [9778369,  ┆ [9782879, ┆ [9782695] ┆ … ┆ [0, 0, …  ┆ [3, 3, …  ┆ [4, 10, … ┆ [0.407408 │\n",
       "│         ┆ 9778381, … ┆ 9780968,  ┆           ┆   ┆ 1]        ┆ 4]        ┆ 7]        ┆ ,         │\n",
       "│         ┆ 9778971]   ┆ …         ┆           ┆   ┆           ┆           ┆           ┆ 0.088169, │\n",
       "│         ┆            ┆ 9782695]  ┆           ┆   ┆           ┆           ┆           ┆ …         │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆           ┆ 0.358567] │\n",
       "│ 1216284 ┆ [9778769,  ┆ [7213923, ┆ [9780651] ┆ … ┆ [0, 0, …  ┆ [42295,   ┆ [0, 0, …  ┆ [0.40595, │\n",
       "│         ┆ 9778745, … ┆ 9052240,  ┆           ┆   ┆ 1]        ┆ 12288, …  ┆ 1]        ┆ 0.09089,  │\n",
       "│         ┆ 9778827]   ┆ …         ┆           ┆   ┆           ┆ 0]        ┆           ┆ …         │\n",
       "│         ┆            ┆ 9780651]  ┆           ┆   ┆           ┆           ┆           ┆ 0.347896] │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.57,\n",
       "    \"mrr\": 0.5053333333333333,\n",
       "    \"ndcg@5\": 0.6274650294492777,\n",
       "    \"ndcg@10\": 0.6274650294492777\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=df_validation[\"labels\"].to_list(),\n",
    "    predictions=df_validation[\"predicted_scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
